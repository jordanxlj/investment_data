import os
import time
import datetime
from typing import Optional, List, Dict, Any
from functools import wraps

import fire
import pandas as pd
import numpy as np
import tushare as ts
from sqlalchemy import create_engine, text
from sqlalchemy import Table, MetaData
from sqlalchemy.dialects.mysql import insert as mysql_insert
import pymysql  # noqa: F401 - required by SQLAlchemy URL


# Tushare init
ts.set_token(os.environ["TUSHARE"])  # expects env var set
pro = ts.pro_api()


def retry_on_failure(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """
    Decorator: Add retry mechanism to function

    Args:
        max_retries: Maximum number of retries
        delay: Initial delay time (seconds)
        backoff: Delay multiplier
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay

            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e

                    if attempt < max_retries:
                        print(f"Function {func.__name__} call failed (attempt {attempt + 1}/{max_retries + 1}): {e}")
                        print(f"Waiting {current_delay:.1f} seconds before retry...")
                        time.sleep(current_delay)
                        current_delay *= backoff  # exponential backoff
                    else:
                        print(f"Function {func.__name__} failed after {max_retries + 1} attempts: {e}")
                        raise last_exception

            # This line won't be executed, but for type checker
            raise last_exception

        return wrapper
    return decorator


def call_tushare_api_with_retry(api_func, *args, **kwargs):
    """
    Generic Tushare API call function with retry mechanism

    Args:
        api_func: Tushare API function
        *args: Positional arguments
        **kwargs: Keyword arguments

    Returns:
        DataFrame returned by API
    """
    @retry_on_failure(max_retries=3, delay=1.0, backoff=2.0)
    def _call_api():
        return api_func(*args, **kwargs)

    return _call_api()


TABLE_NAME = "ts_a_stock_financial_profile"


CREATE_TABLE_DDL = f"""
CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
  ts_code                   VARCHAR(16)  NOT NULL,
  report_period             DATE         NOT NULL,
  period                    VARCHAR(8)   NOT NULL,
  currency                  VARCHAR(3)   NOT NULL,
  ann_date                  DATE         NULL,

  -- Income statement fields (ä¸‡å…ƒå­˜å‚¨ - converted from å…ƒ)
  total_revenue             DECIMAL(16,4) NULL COMMENT 'æ€»è¥æ”¶(ä¸‡å…ƒ)',
  revenue                   DECIMAL(16,4) NULL COMMENT 'è¥ä¸šæ”¶å…¥(ä¸‡å…ƒ)',
  operate_profit            DECIMAL(16,4) NULL COMMENT 'è¥ä¸šåˆ©æ¶¦(ä¸‡å…ƒ)',
  total_profit              DECIMAL(16,4) NULL COMMENT 'åˆ©æ¶¦æ€»é¢(ä¸‡å…ƒ)',
  n_income_attr_p           DECIMAL(16,4) NULL COMMENT 'å‡€åˆ©æ¶¦(ä¸‡å…ƒ)',
  basic_eps                 FLOAT NULL COMMENT 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)',
  total_cogs                DECIMAL(16,4) NULL COMMENT 'è¥ä¸šæ€»æˆæœ¬(ä¸‡å…ƒ)',
  oper_cost                 DECIMAL(16,4) NULL COMMENT 'è¥ä¸šæˆæœ¬(ä¸‡å…ƒ)',
  sell_exp                  DECIMAL(16,4) NULL COMMENT 'é”€å”®è´¹ç”¨(ä¸‡å…ƒ)',
  admin_exp                 DECIMAL(16,4) NULL COMMENT 'ç®¡ç†è´¹ç”¨(ä¸‡å…ƒ)',
  fin_exp                   DECIMAL(16,4) NULL COMMENT 'è´¢åŠ¡è´¹ç”¨(ä¸‡å…ƒ)',
  invest_income             DECIMAL(16,4) NULL COMMENT 'æŠ•èµ„æ”¶ç›Š(ä¸‡å…ƒ)',
  interest_exp              DECIMAL(16,4) NULL COMMENT 'åˆ©æ¯æ”¯å‡º(ä¸‡å…ƒ)',
  oper_exp                  DECIMAL(16,4) NULL COMMENT 'è¥ä¸šæ”¯å‡º(ä¸‡å…ƒ)',
  ebit                      DECIMAL(16,4) NULL COMMENT 'æ¯ç¨Žå‰åˆ©æ¶¦(ä¸‡å…ƒ)',
  ebitda                    DECIMAL(16,4) NULL COMMENT 'EBITDA(ä¸‡å…ƒ)',
  income_tax                DECIMAL(16,4) NULL COMMENT 'æ‰€å¾—ç¨Ž(ä¸‡å…ƒ)',
  comshare_payable_dvd      DECIMAL(16,4) NULL COMMENT 'åº”ä»˜è‚¡åˆ©(ä¸‡å…ƒ)',

  -- Balance sheet fields (ä¸‡å…ƒå­˜å‚¨ - converted from å…ƒ)
  total_assets              DECIMAL(16,4) NULL COMMENT 'æ€»èµ„äº§(ä¸‡å…ƒ)',
  total_liab                DECIMAL(16,4) NULL COMMENT 'æ€»è´Ÿå€º(ä¸‡å…ƒ)',
  total_equity              DECIMAL(16,4) NULL COMMENT 'è‚¡ä¸œæƒç›Š(ä¸‡å…ƒ)',
  total_hldr_eqy_exc_min_int DECIMAL(16,4) NULL COMMENT 'è‚¡ä¸œæƒç›Š(ä¸å«å°‘æ•°è‚¡ä¸œæƒç›Š)(ä¸‡å…ƒ)',
  total_hldr_eqy_inc_min_int DECIMAL(16,4) NULL COMMENT 'è‚¡ä¸œæƒç›Š(å«å°‘æ•°è‚¡ä¸œæƒç›Š)(ä¸‡å…ƒ)',
  total_cur_assets          DECIMAL(16,4) NULL COMMENT 'æµåŠ¨èµ„äº§(ä¸‡å…ƒ)',
  total_cur_liab            DECIMAL(16,4) NULL COMMENT 'æµåŠ¨è´Ÿå€º(ä¸‡å…ƒ)',
  accounts_receiv           DECIMAL(16,4) NULL COMMENT 'åº”æ”¶è´¦æ¬¾(ä¸‡å…ƒ)',
  inventories               DECIMAL(16,4) NULL COMMENT 'å­˜è´§(ä¸‡å…ƒ)',
  acct_payable              DECIMAL(16,4) NULL COMMENT 'åº”ä»˜è´¦æ¬¾(ä¸‡å…ƒ)',
  fix_assets                DECIMAL(16,4) NULL COMMENT 'å›ºå®šèµ„äº§(ä¸‡å…ƒ)',
  lt_borr                   DECIMAL(16,4) NULL COMMENT 'é•¿æœŸå€Ÿæ¬¾(ä¸‡å…ƒ)',
  r_and_d                   DECIMAL(16,4) NULL COMMENT 'ç ”å‘æ”¯å‡º(ä¸‡å…ƒ)',
  goodwill                  DECIMAL(16,4) NULL COMMENT 'å•†èª‰(ä¸‡å…ƒ)',
  intang_assets             DECIMAL(16,4) NULL COMMENT 'æ— å½¢èµ„äº§(ä¸‡å…ƒ)',
  st_borr                   DECIMAL(16,4) NULL COMMENT 'çŸ­æœŸå€Ÿæ¬¾(ä¸‡å…ƒ)',
  total_share               DECIMAL(16,4) NULL COMMENT 'è‚¡æœ¬(ä¸‡å…ƒ)',
  oth_eqt_tools_p_shr       DECIMAL(16,4) NULL COMMENT 'å…¶ä»–æƒç›Šå·¥å…·(ä¸‡å…ƒ)',

  -- Cash flow statement fields (ä¸‡å…ƒå­˜å‚¨ - converted from å…ƒ)
  n_cashflow_act            DECIMAL(16,4) NULL COMMENT 'ç»è¥çŽ°é‡‘æµ(ä¸‡å…ƒ)',
  n_cashflow_inv_act        DECIMAL(16,4) NULL COMMENT 'æŠ•èµ„çŽ°é‡‘æµ(ä¸‡å…ƒ)',
  n_cash_flows_fnc_act      DECIMAL(16,4) NULL COMMENT 'èžèµ„çŽ°é‡‘æµ(ä¸‡å…ƒ)',
  free_cashflow             DECIMAL(16,4) NULL COMMENT 'è‡ªç”±çŽ°é‡‘æµ(ä¸‡å…ƒ)',
  c_pay_acq_const_fiolta    DECIMAL(16,4) NULL COMMENT 'è´­å»ºå›ºå®šèµ„äº§(ä¸‡å…ƒ)',
  c_fr_sale_sg              DECIMAL(16,4) NULL COMMENT 'é”€å”®å•†å“æ”¶æ¬¾(ä¸‡å…ƒ)',
  c_paid_goods_s            DECIMAL(16,4) NULL COMMENT 'è´­ä¹°å•†å“ä»˜æ¬¾(ä¸‡å…ƒ)',
  c_paid_to_for_empl        DECIMAL(16,4) NULL COMMENT 'æ”¯ä»˜èŒå·¥è–ªé…¬(ä¸‡å…ƒ)',
  c_paid_for_taxes          DECIMAL(16,4) NULL COMMENT 'æ”¯ä»˜ç¨Žè´¹(ä¸‡å…ƒ)',
  n_incr_cash_cash_equ      DECIMAL(16,4) NULL COMMENT 'çŽ°é‡‘ç­‰ä»·ç‰©å‡€å¢žåŠ (ä¸‡å…ƒ)',
  c_disp_withdrwl_invest    DECIMAL(16,4) NULL COMMENT 'å¤„ç½®æŠ•èµ„æ”¶æ¬¾(ä¸‡å…ƒ)',
  c_pay_dist_dpcp_int_exp   DECIMAL(16,4) NULL COMMENT 'åˆ†é…è‚¡åˆ©åˆ©æ¯(ä¸‡å…ƒ)',
  c_cash_equ_end_period     DECIMAL(16,4) NULL COMMENT 'æœŸæœ«çŽ°é‡‘ä½™é¢(ä¸‡å…ƒ)',

  -- === Financial indicator fields (grouped by relevance) ===

  -- 1. Basic financial indicators
  eps                       FLOAT NULL COMMENT 'æ¯è‚¡æ”¶ç›Š(å…ƒ)',
  dt_eps                    FLOAT NULL COMMENT 'ç¨€é‡Šæ¯è‚¡æ”¶ç›Š(å…ƒ)',
  netprofit_margin          FLOAT NULL COMMENT 'å‡€åˆ©çŽ‡(%)',
  grossprofit_margin        FLOAT NULL COMMENT 'æ¯›åˆ©æ¶¦çŽ‡(%)',
  ebitda_margin             FLOAT NULL COMMENT 'EBITDAåˆ©æ¶¦çŽ‡(%)',
  gross_margin              DECIMAL(16,4) NULL COMMENT 'æ¯›åˆ©(å…ƒ)',
  extra_item                DECIMAL(16,4) NULL COMMENT 'å…¶ä»–é¡¹ç›®(ä¸‡å…ƒ)',
  profit_dedt               DECIMAL(16,4) NULL COMMENT 'æ‰£é™¤éžç»å¸¸æ€§æŸç›ŠåŽçš„å‡€åˆ©æ¶¦(ä¸‡å…ƒ)',
  op_income                 DECIMAL(16,4) NULL COMMENT 'è¥ä¸šæ”¶å…¥(ä¸‡å…ƒ)',
  daa                       DECIMAL(16,4) NULL COMMENT 'æŠ˜æ—§å’Œæ‘Šé”€(ä¸‡å…ƒ)',
  rd_exp                    DECIMAL(16,4) NULL COMMENT 'ç ”å‘è´¹ç”¨(ä¸‡å…ƒ)',

  -- 2. Solvency indicators (ratios - no unit conversion needed)
  current_ratio             FLOAT NULL COMMENT 'æµåŠ¨æ¯”çŽ‡',
  quick_ratio               FLOAT NULL COMMENT 'é€ŸåŠ¨æ¯”çŽ‡',
  cash_ratio                FLOAT NULL COMMENT 'çŽ°é‡‘æ¯”çŽ‡',
  debt_to_assets            FLOAT NULL COMMENT 'èµ„äº§è´Ÿå€ºçŽ‡',
  assets_to_eqt             FLOAT NULL COMMENT 'æƒç›Šä¹˜æ•°',
  dp_assets_to_eqt          FLOAT NULL COMMENT 'æœ‰å½¢èµ„äº§æƒç›Šä¹˜æ•°',
  debt_to_eqt               FLOAT NULL COMMENT 'äº§æƒæ¯”çŽ‡',
  eqt_to_debt               FLOAT NULL COMMENT 'å‡€èµ„äº§è´Ÿå€ºçŽ‡å€’æ•°',
  eqt_to_interestdebt       FLOAT NULL COMMENT 'å‡€èµ„äº§åˆ©æ¯è´Ÿæ‹…çŽ‡å€’æ•°',
  ebit_to_interest          FLOAT NULL COMMENT 'åˆ©æ¯ä¿éšœå€æ•°',
  ebitda_to_debt            FLOAT NULL COMMENT 'EBITDAå¯¹å€ºåŠ¡æ¯”çŽ‡',
  debt_to_assets_2          FLOAT NULL COMMENT 'èµ„äº§è´Ÿå€ºçŽ‡(å¤‡é€‰)',
  assets_to_eqt_2           FLOAT NULL COMMENT 'æƒç›Šä¹˜æ•°(å¤‡é€‰)',
  dp_assets_to_eqt_2        FLOAT NULL COMMENT 'æœ‰å½¢èµ„äº§æƒç›Šä¹˜æ•°(å¤‡é€‰)',
  tangibleasset_to_debt     FLOAT NULL COMMENT 'æœ‰å½¢èµ„äº§å€ºåŠ¡çŽ‡',
  tangasset_to_intdebt      FLOAT NULL COMMENT 'æœ‰å½¢èµ„äº§åˆ©æ¯å€ºåŠ¡çŽ‡',
  tangibleasset_to_netdebt  FLOAT NULL COMMENT 'æœ‰å½¢èµ„äº§å‡€å€ºåŠ¡çŽ‡',

  -- 3. Operating efficiency indicators
  invturn_days              FLOAT NULL,
  arturn_days               FLOAT NULL,
  turn_days                 FLOAT NULL,
  inv_turn                  FLOAT NULL,
  ar_turn                   FLOAT NULL,
  ca_turn                   FLOAT NULL,
  fa_turn                   FLOAT NULL,
  assets_turn               FLOAT NULL,
  inventory_turnover        FLOAT NULL,
  inventory_days            FLOAT NULL,
  currentasset_turnover     FLOAT NULL,
  currentasset_days         FLOAT NULL,
  arturnover                FLOAT NULL,
  arturndays                FLOAT NULL,

  -- 4. Profitability indicators (ROE/ROA etc.)
  roic                      FLOAT NULL,
  roe_waa                   FLOAT NULL,
  roe_dt                    FLOAT NULL,
  roe_yearly                FLOAT NULL,
  roa                       FLOAT NULL,
  npta                      FLOAT NULL,
  npta_yearly               FLOAT NULL,
  roa_yearly                FLOAT NULL,
  roa_dp                    FLOAT NULL,
  roa_yearly_2              FLOAT NULL,
  roa_dp_2                  FLOAT NULL,
  roa_yearly_3              FLOAT NULL,
  roa_dp_3                  FLOAT NULL,

  -- 5. DuPont analysis indicators
  equity_multiplier         FLOAT NULL,
  roe_waa_2                 FLOAT NULL,
  roe_avg                   FLOAT NULL,
  roe_waa_2_dedt            FLOAT NULL,
  roe_avg_dedt              FLOAT NULL,
  roe_waa_2_nonr            FLOAT NULL,
  roe_avg_nonr              FLOAT NULL,
  roe_waa_2_dedt_ttm        FLOAT NULL,
  roe_dt_2                  FLOAT NULL,
  debt_to_equity_1          FLOAT NULL,
  equity_ratio              FLOAT NULL,

  -- 6. Per share indicators
  total_revenue_ps          FLOAT NULL,
  revenue_ps                FLOAT NULL,
  capital_rese_ps           FLOAT NULL,
  surplus_rese_ps           FLOAT NULL,
  undist_profit_ps          FLOAT NULL,
  bps                       FLOAT NULL,
  ocfps                     FLOAT NULL,
  retainedps                FLOAT NULL,
  cfps                      FLOAT NULL,
  ebit_ps                   FLOAT NULL,
  fcff_ps                   FLOAT NULL,
  fcfe_ps                   FLOAT NULL,
  q_eps                     FLOAT NULL,

  -- 7. Cash flow indicators
  cf_sales                  FLOAT NULL,
  cf_nm                     FLOAT NULL,
  cf_liabs                  FLOAT NULL,
  cashflow_m                FLOAT NULL,
  op_of_gr                  FLOAT NULL,
  ocf_to_debt               FLOAT NULL,
  ocf_to_interestdebt       FLOAT NULL,
  ocf_to_netdebt            FLOAT NULL,
  ocf_to_shortdebt          FLOAT NULL,
  ocf_to_or                 FLOAT NULL,
  ocf_to_opincome           FLOAT NULL,
  salescash_to_or           FLOAT NULL,
  q_ocf_to_sales            FLOAT NULL,

  -- 8. Growth indicators (YoY growth rates)
  basic_eps_yoy             FLOAT NULL,
  dt_eps_yoy                FLOAT NULL,
  cfps_yoy                  FLOAT NULL,
  op_yoy                    FLOAT NULL,
  ebt_yoy                   FLOAT NULL,
  netprofit_yoy             FLOAT NULL,
  dt_netprofit_yoy          FLOAT NULL,
  ocf_yoy                   FLOAT NULL,
  roe_yoy                   FLOAT NULL,
  bps_yoy                   FLOAT NULL,
  assets_yoy                FLOAT NULL,
  eqt_yoy                   FLOAT NULL,
  tr_yoy                    FLOAT NULL,
  or_yoy                    FLOAT NULL,
  equity_yoy                FLOAT NULL,

  -- 9. Quarterly financial indicators
  q_opincome                DECIMAL(16,4) NULL,
  q_investincome            DECIMAL(16,4) NULL,
  q_dtprofit                DECIMAL(16,4) NULL,
  q_netprofit_margin        FLOAT NULL,
  q_gsprofit_margin         FLOAT NULL,
  q_exp_to_sales            FLOAT NULL,
  q_profit_to_gr            FLOAT NULL,
  q_saleexp_to_gr           FLOAT NULL,
  q_adminexp_to_gr          FLOAT NULL,
  q_finaexp_to_gr           FLOAT NULL,
  q_impair_to_gr_ttm        FLOAT NULL,
  q_gc_to_gr                FLOAT NULL,
  q_op_to_gr                FLOAT NULL,
  q_roe                     FLOAT NULL,
  q_dt_roe                  FLOAT NULL,
  q_npta                    FLOAT NULL,

  -- 10. Quarterly sequential growth rates
  q_gr_yoy                  FLOAT NULL,
  q_gr_qoq                  FLOAT NULL,
  q_sales_yoy               FLOAT NULL,
  q_sales_qoq               FLOAT NULL,
  q_op_yoy                  FLOAT NULL,
  q_op_qoq                  FLOAT NULL,
  q_profit_yoy              FLOAT NULL,
  q_profit_qoq              FLOAT NULL,
  q_netprofit_yoy           FLOAT NULL,
  q_netprofit_qoq           FLOAT NULL,

  -- 11. Cost and expense structure analysis
  cogs_of_sales             FLOAT NULL,
  expense_of_sales          FLOAT NULL,
  profit_to_gr              FLOAT NULL,
  saleexp_to_gr             FLOAT NULL,
  adminexp_to_gr            FLOAT NULL,
  finaexp_to_gr             FLOAT NULL,
  impair_to_gr_ttm          FLOAT NULL,
  gc_of_gr                  FLOAT NULL,
  op_to_ebt                 FLOAT NULL,
  tax_to_ebt                FLOAT NULL,
  dtprofit_to_profit        FLOAT NULL,
  profit_to_op              FLOAT NULL,
  profit_prefin_exp         DECIMAL(16,4) NULL,
  non_op_profit             DECIMAL(16,4) NULL,

  -- 12. Asset structure analysis
  ca_to_assets              FLOAT NULL,
  nca_to_assets             FLOAT NULL,
  tbassets_to_totalassets   FLOAT NULL,
  fixed_assets              DECIMAL(16,4) NULL,
  int_to_talcap             FLOAT NULL,
  eqt_to_talcapital         FLOAT NULL,
  currentdebt_to_debt       FLOAT NULL,
  longdeb_to_debt           FLOAT NULL,
  longdebt_to_workingcapital FLOAT NULL,
  capitalized_to_da         FLOAT NULL,

  -- 13. Valuation indicators
  current_exint             DECIMAL(16,4) NULL,
  non_current_exint         DECIMAL(16,4) NULL,
  intrinsicvalue            DECIMAL(16,4) NULL,
  tmv                       DECIMAL(16,4) NULL,
  lmv                       DECIMAL(16,4) NULL,

  -- TTM (Trailing Twelve Months) indicators
  eps_ttm                   FLOAT NULL COMMENT 'TTMæ¯è‚¡æ”¶ç›Š(å…ƒ)',
  revenue_ps_ttm            FLOAT NULL COMMENT 'TTMæ¯è‚¡è¥æ”¶(å…ƒ)',
  ocfps_ttm                 FLOAT NULL COMMENT 'TTMæ¯è‚¡ç»è¥çŽ°é‡‘æµ(å…ƒ)',
  cfps_ttm                  FLOAT NULL COMMENT 'TTMæ¯è‚¡çŽ°é‡‘æµ(å…ƒ)',
  roe_ttm                   FLOAT NULL COMMENT 'TTMå‡€èµ„äº§æ”¶ç›ŠçŽ‡(%)',
  roa_ttm                   FLOAT NULL COMMENT 'TTMæ€»èµ„äº§æŠ¥é…¬çŽ‡(%)',
  netprofit_margin_ttm      FLOAT NULL COMMENT 'TTMå‡€åˆ©çŽ‡(%)',
  grossprofit_margin_ttm    FLOAT NULL COMMENT 'TTMæ¯›åˆ©çŽ‡(%)',
  revenue_cagr_3y           FLOAT NULL COMMENT 'è¥æ”¶ä¸‰å¹´å¤åˆå¢žé•¿çŽ‡(%)',
  netincome_cagr_3y         FLOAT NULL COMMENT 'å‡€åˆ©æ¶¦ä¸‰å¹´å¤åˆå¢žé•¿çŽ‡(%)',
  roic_ttm                  FLOAT NULL COMMENT 'TTMæŠ•èµ„å›žæŠ¥çŽ‡(%)',
  fcf_ttm                   DECIMAL(16,4) NULL COMMENT 'TTMè‡ªç”±çŽ°é‡‘æµ(ä¸‡å…ƒ)',
  fcf_margin_ttm            FLOAT NULL COMMENT 'TTMè‡ªç”±çŽ°é‡‘æµçŽ‡(%)',
  debt_to_ebitda_ttm        FLOAT NULL COMMENT 'TTMå€ºåŠ¡/EBITDAæ¯”çŽ‡',

  PRIMARY KEY (ts_code, report_period),
  INDEX idx_ann_date (ann_date),
  INDEX idx_report_period (report_period),
  INDEX idx_ts_code_ann_date (ts_code, ann_date),
  INDEX idx_ts_code_report_period_ann_date (ts_code, report_period, ann_date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;
"""


# === Data source field grouping definitions ===

# Base fields (shared by all data sources)
BASE_COLUMNS = ["ts_code", "ann_date", "report_period", "period", "currency"]

# Income statement fields
INCOME_COLUMNS = [
    "total_revenue", "revenue", "operate_profit", "total_profit", "n_income_attr_p", "basic_eps",
    "total_cogs", "oper_cost", "sell_exp", "admin_exp", "fin_exp", "invest_income", "interest_exp",
    "oper_exp", "ebit", "ebitda", "income_tax", "comshare_payable_dvd", "rd_exp"
]

# Balance sheet fields
BALANCE_COLUMNS = [
    "total_assets", "total_liab", "total_hldr_eqy_inc_min_int", "total_cur_assets",
    "total_cur_liab", "accounts_receiv", "inventories", "acct_payable",
    "fix_assets", "lt_borr", "r_and_d", "goodwill", "intang_assets", "st_borr",
    "total_share", "oth_eqt_tools_p_shr", "total_hldr_eqy_exc_min_int"
]

# Cash flow statement fields
CASHFLOW_COLUMNS = [
    "n_cashflow_act", "n_cashflow_inv_act", "n_cash_flows_fnc_act",
    "free_cashflow", "c_pay_acq_const_fiolta", "c_fr_sale_sg", "c_paid_goods_s",
    "c_paid_to_for_empl", "c_paid_for_taxes", "n_incr_cash_cash_equ",
    "c_disp_withdrwl_invest", "c_pay_dist_dpcp_int_exp", "c_cash_equ_end_period"
]

# Financial indicator fields (grouped by relevance)
INDICATOR_COLUMNS = [
    # Basic financial indicators
    "eps", "dt_eps", "gross_margin", "netprofit_margin", "grossprofit_margin",
    "ebitda_margin", "extra_item", "profit_dedt", "op_income", "daa",

    # Solvency indicators
    "current_ratio", "quick_ratio", "cash_ratio", "debt_to_assets", "assets_to_eqt",
    "dp_assets_to_eqt", "debt_to_eqt", "eqt_to_debt", "eqt_to_interestdebt",
    "ebit_to_interest", "ebitda_to_debt", "debt_to_assets_2", "assets_to_eqt_2",
    "dp_assets_to_eqt_2", "tangibleasset_to_debt", "tangasset_to_intdebt",
    "tangibleasset_to_netdebt",

    # Operating efficiency indicators
    "invturn_days", "arturn_days", "turn_days", "inv_turn", "ar_turn", "ca_turn",
    "fa_turn", "assets_turn", "inventory_turnover", "inventory_days",
    "currentasset_turnover", "currentasset_days", "arturnover", "arturndays",

    # Profitability indicators (ROE/ROA etc.)
    "roic", "roe_waa", "roe_dt", "roe_yearly", "roa", "npta", "npta_yearly",
    "roa_yearly", "roa_dp", "roa_yearly_2", "roa_dp_2", "roa_yearly_3", "roa_dp_3",

    # DuPont analysis indicators
    "equity_multiplier", "roe_waa_2", "roe_avg", "roe_waa_2_dedt", "roe_avg_dedt",
    "roe_waa_2_nonr", "roe_avg_nonr", "roe_waa_2_dedt_ttm", "roe_dt_2",
    "debt_to_equity_1", "equity_ratio",

    # Per share indicators
    "total_revenue_ps", "revenue_ps", "capital_rese_ps", "surplus_rese_ps",
    "undist_profit_ps", "bps", "ocfps", "retainedps", "cfps", "ebit_ps",
    "fcff_ps", "fcfe_ps", "q_eps",

    # Cash flow indicators
    "cf_sales", "cf_nm", "cf_liabs", "cashflow_m", "op_of_gr", "ocf_to_debt",
    "ocf_to_interestdebt", "ocf_to_netdebt", "ocf_to_shortdebt", "ocf_to_or",
    "ocf_to_opincome", "salescash_to_or", "q_ocf_to_sales",

    # Growth indicators (YoY growth rates)
    "basic_eps_yoy", "dt_eps_yoy", "cfps_yoy", "op_yoy", "ebt_yoy", "netprofit_yoy",
    "dt_netprofit_yoy", "ocf_yoy", "roe_yoy", "bps_yoy", "assets_yoy", "eqt_yoy",
    "tr_yoy", "or_yoy", "equity_yoy",

    # Quarterly financial indicators
    "q_opincome", "q_investincome", "q_dtprofit", "q_netprofit_margin",
    "q_gsprofit_margin", "q_exp_to_sales", "q_profit_to_gr", "q_saleexp_to_gr",
    "q_adminexp_to_gr", "q_finaexp_to_gr", "q_impair_to_gr_ttm", "q_gc_to_gr",
    "q_op_to_gr", "q_roe", "q_dt_roe", "q_npta",

    # Quarterly sequential growth rates
    "q_gr_yoy", "q_gr_qoq", "q_sales_yoy", "q_sales_qoq", "q_op_yoy", "q_op_qoq",
    "q_profit_yoy", "q_profit_qoq", "q_netprofit_yoy", "q_netprofit_qoq",

    # Cost and expense structure analysis
    "cogs_of_sales", "expense_of_sales", "profit_to_gr", "saleexp_to_gr",
    "adminexp_to_gr", "finaexp_to_gr", "impair_to_gr_ttm", "gc_of_gr",
    "op_to_ebt", "tax_to_ebt", "dtprofit_to_profit", "profit_to_op",
    "profit_prefin_exp", "non_op_profit",

    # Asset structure analysis
    "ca_to_assets", "nca_to_assets", "tbassets_to_totalassets", "fixed_assets",
    "int_to_talcap", "eqt_to_talcapital", "currentdebt_to_debt", "longdeb_to_debt",
    "longdebt_to_workingcapital", "capitalized_to_da",

    # Valuation indicators
    "current_exint", "non_current_exint", "intrinsicvalue", "tmv", "lmv",

    # TTM (Trailing Twelve Months) indicators
    "eps_ttm", "revenue_ps_ttm", "ocfps_ttm", "cfps_ttm",
    "roe_ttm", "roa_ttm", "netprofit_margin_ttm", "grossprofit_margin_ttm",
    "revenue_cagr_3y", "netincome_cagr_3y",
    "roic_ttm", "fcf_ttm", "fcf_margin_ttm", "debt_to_ebitda_ttm"
]

# === Data source field configuration ===

# API field name list (all three major financial statements contain these base fields)
# Note: API returns 'end_date' but database stores as 'ann_date'
API_COMMON_FIELDS = ['ts_code', 'ann_date', 'end_date', 'report_type']

# Financial indicators base fields (does not include report_type)
INDICATOR_BASE_FIELDS = ['ts_code', 'ann_date', 'end_date']  # Keep end_date for API call, will be mapped later

# === Merged total field list (used for database operations) ===
ALL_COLUMNS: List[str] = BASE_COLUMNS + INCOME_COLUMNS + BALANCE_COLUMNS + CASHFLOW_COLUMNS + INDICATOR_COLUMNS

# Fields that need conversion from å…ƒ to ä¸‡å…ƒ for storage
# These are monetary amount fields (not ratios or per-share metrics)
YUAN_TO_WAN_FIELDS = [
    # Income statement - main monetary amounts
    'total_revenue', 'revenue', 'operate_profit', 'total_profit', 'n_income_attr_p',
    'total_cogs', 'oper_cost', 'sell_exp', 'admin_exp', 'fin_exp', 'invest_income',
    'interest_exp', 'oper_exp', 'ebit', 'ebitda', 'income_tax',
    'comshare_payable_dvd', 'rd_exp',

    # Balance sheet - main monetary amounts
    'total_assets', 'total_liab', 'total_cur_assets', 'total_cur_liab', 
    'accounts_receiv', 'inventories', 'acct_payable', 'fix_assets', 
    'lt_borr', 'r_and_d', 'goodwill', 'intang_assets', 'st_borr',
    'total_share', 'oth_eqt_tools_p_shr', 'total_hldr_eqy_exc_min_int', 
    'total_hldr_eqy_inc_min_int',

    # Cash flow statement - main monetary amounts
    'n_cashflow_act', 'n_cashflow_inv_act', 'n_cash_flows_fnc_act',
    'free_cashflow', 'c_pay_acq_const_fiolta', 'c_fr_sale_sg',
    'c_paid_goods_s', 'c_paid_to_for_empl', 'c_paid_for_taxes',
    'n_incr_cash_cash_equ', 'c_disp_withdrwl_invest',
    'c_pay_dist_dpcp_int_exp', 'c_cash_equ_end_period',

    # Financial indicators - monetary amounts (not ratios)
    'extra_item', 'profit_dedt', 'op_income', 'daa', 'gross_margin',

    # Quarterly financial indicators
    'q_opincome', 'q_investincome', 'q_dtprofit',

    # Other monetary amounts
    'profit_prefin_exp', 'non_op_profit', 'fixed_assets',

    # TTM monetary amounts
    'fcf_ttm',

    # Valuation indicators
    'current_exint', 'non_current_exint', 'intrinsicvalue', 'tmv', 'lmv'
]

# Per-share metrics that should remain in å…ƒ (not converted)
PER_SHARE_FIELDS = [
    'eps', 'dt_eps', 'basic_eps', 'q_eps',
    'bps', 'ocfps', 'retainedps', 'cfps', 'ebit_ps', 'fcff_ps', 'fcfe_ps'
]

# TTM indicator fields to add to database schema
TTM_COLUMNS = [
    # TTM basic financial indicators
    'eps_ttm', 'revenue_ps_ttm', 'ocfps_ttm', 'cfps_ttm',
    'roe_ttm', 'roa_ttm', 'netprofit_margin_ttm', 'grossprofit_margin_ttm',

    # TTM growth indicators
    'revenue_cagr_3y', 'netincome_cagr_3y',

    # TTM efficiency and quality indicators
    'roic_ttm', 'fcf_ttm', 'fcf_margin_ttm', 'debt_to_ebitda_ttm'
]


def calculate_quarterly_values(group, columns):
    """Calculate quarterly values using vectorized operations within each year"""
    group = group.sort_values('report_period')
    group['year'] = group['report_period'].str[:4]
    for col in columns:
        group['q_' + col] = group.groupby('year')[col].diff().fillna(group[col])
    return group.drop(columns=['year'])


def calculate_ttm_indicators(df):
    """
    Vectorized calculation of TTM indicators.
    Assumes df has 'ts_code', 'report_period', and required columns.
    Returns df with added TTM columns.
    """
    if df.empty:
        return df

    # è½¬æ¢ä¸ºdatetimeä»¥ä¾¿å¤„ç†æ—¶é—´åºåˆ—
    df['report_date'] = pd.to_datetime(df['report_period'], format='%Y%m%d')

    # ä¸ºæ¯ä¸ªts_codeè¡¥å…¨ä¸­é—´ç¼ºå¤±çš„å­£åº¦åºåˆ—
    def complete_quarters(ts_code_group):
        ts_code, group = ts_code_group

        # æ‰¾åˆ°å®žé™…å­˜åœ¨æ•°æ®çš„æ—¥æœŸèŒƒå›´
        existing_dates = group['report_date'].dropna().sort_values()

        if len(existing_dates) < 2:
            # å¦‚æžœæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•ç¡®å®šè¡¥å…¨èŒƒå›´ï¼Œç›´æŽ¥è¿”å›žåŽŸæ•°æ®
            group_copy = group.copy()
            group_copy['missing'] = 0  # æ ‡è®°ä¸ºéžç¼ºå¤±
            group_copy['missing_type'] = 'insufficient_data'
            return group_copy

        min_date = existing_dates.min()
        max_date = existing_dates.max()

        # ç”Ÿæˆä»Žæœ€æ—©æ•°æ®åˆ°æœ€æ™šæ•°æ®çš„å®Œæ•´å­£åº¦æœ«åºåˆ—
        full_dates = pd.date_range(start=min_date, end=max_date, freq='QE-SEP')
        full_df = pd.DataFrame({'report_date': full_dates})
        full_df['report_period'] = full_df['report_date'].dt.strftime('%Y%m%d')
        full_df['ts_code'] = ts_code  # æ·»åŠ ts_code

        # å·¦åˆå¹¶åŽŸæ•°æ®ï¼Œç¼ºå¤±å¤„NA
        merged = pd.merge(full_df, group, on=['ts_code', 'report_period', 'report_date'], how='left')

        # åˆ†æžç¼ºå¤±æ¨¡å¼
        missing_mask = merged['n_income_attr_p'].isna()
        merged['missing'] = missing_mask.astype(int)

        # è¯†åˆ«ç¼ºå¤±ç±»åž‹
        merged['missing_type'] = 'none'
        merged.loc[missing_mask, 'missing_type'] = 'data_missing'

        # è¿›ä¸€æ­¥åˆ†ç±»ç¼ºå¤±ç±»åž‹
        existing_periods = set(group['report_period'].dropna())
        if existing_periods:
            min_existing_period = min(existing_periods)
            max_existing_period = max(existing_periods)

            # ä¸¤å¤´ç¼ºå¤±ï¼šæ•°æ®èŒƒå›´å¤–çš„ç¼ºå¤±
            outside_range = (merged['report_period'] < min_existing_period) | (merged['report_period'] > max_existing_period)
            merged.loc[missing_mask & outside_range, 'missing_type'] = 'edge_missing'

            # ä¸­é—´ç¼ºå¤±ï¼šæ•°æ®èŒƒå›´å†…çš„ç¼ºå¤±
            inside_range = (merged['report_period'] >= min_existing_period) & (merged['report_period'] <= max_existing_period)
            merged.loc[missing_mask & inside_range, 'missing_type'] = 'intermediate_missing'

            # è®°å½•ä¸åŒç±»åž‹çš„ç¼ºå¤±
            intermediate_missing = merged[(merged['missing_type'] == 'intermediate_missing')]
            if not intermediate_missing.empty:
                missing_periods = intermediate_missing['report_period'].tolist()
                print(f"âš ï¸  {ts_code}: ä¸­é—´æ•°æ®ç¼ºå¤± {len(missing_periods)} ä¸ªå­£åº¦: {missing_periods}")

        # ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
        missing_stats = merged['missing_type'].value_counts()
        if missing_stats.get('intermediate_missing', 0) > 0:
            print(f"ðŸ“Š {ts_code}: ç¼ºå¤±ç»Ÿè®¡ - ä¸­é—´:{missing_stats.get('intermediate_missing', 0)}, è¾¹ç¼˜:{missing_stats.get('edge_missing', 0)}, æ•°æ®:{missing_stats.get('data_missing', 0)}")

        return merged

    # ä½¿ç”¨itertools.groupbyæ¥é¿å…pandas groupbyçš„FutureWarning
    import itertools
    df = df.sort_values(['ts_code', 'report_date'])
    groups = []
    for ts_code, group in itertools.groupby(df.iterrows(), key=lambda x: x[1]['ts_code']):
        group_df = pd.DataFrame([row[1] for row in group])
        groups.append((ts_code, group_df))

    completed_groups = [complete_quarters((ts_code, group)) for ts_code, group in groups]
    df = pd.concat(completed_groups, ignore_index=True)

    # æ™ºèƒ½å¡«å……NAæ•°æ®ï¼Œæ ¹æ®ç¼ºå¤±ç±»åž‹é‡‡ç”¨ä¸åŒç­–ç•¥
    print("ðŸ”„ å¼€å§‹æ™ºèƒ½æ•°æ®å¡«å……...")

    # 1. æµæ•°æ®ï¼ˆflow dataï¼‰ï¼šæ”¶å…¥ã€æˆæœ¬ã€çŽ°é‡‘æµç­‰
    # ä¸­é—´ç¼ºå¤±ä½¿ç”¨æ’å€¼ï¼Œä¸¤å¤´ç¼ºå¤±ä¿æŒä¸º0ï¼ˆè¡¨ç¤ºè¯¥æ—¶æœŸæ²¡æœ‰æ•°æ®ï¼‰
    flow_cols = ['n_income_attr_p', 'total_revenue', 'im_net_cashflow_oper_act']
    optional_flow_cols = ['total_cogs', 'oper_cost']
    for col in optional_flow_cols:
        if col in df.columns:
            flow_cols.append(col)

    for col in flow_cols:
        if col in df.columns:
            # å¯¹äºŽä¸­é—´ç¼ºå¤±ï¼Œä½¿ç”¨çº¿æ€§æ’å€¼
            intermediate_mask = df['missing_type'] == 'intermediate_missing'
            if intermediate_mask.any():
                # å¯¹æ¯ä¸ªè‚¡ç¥¨åˆ†åˆ«è¿›è¡Œæ’å€¼
                df[col] = df.groupby('ts_code')[col].transform(lambda x: x.interpolate(method='linear', limit_direction='both'))

            # å¯¹äºŽä¸¤å¤´ç¼ºå¤±å’Œæ•°æ®ç¼ºå¤±ï¼Œå¡«å……ä¸º0ï¼ˆè¡¨ç¤ºè¯¥æ—¶æœŸæ²¡æœ‰å‘ç”Ÿï¼‰
            edge_data_mask = (df['missing_type'] == 'edge_missing') | (df['missing_type'] == 'data_missing')
            df.loc[edge_data_mask, col] = df.loc[edge_data_mask, col].fillna(0)

    # 2. å­˜é‡æ•°æ®ï¼ˆstock dataï¼‰ï¼šèµ„äº§ã€è´Ÿå€ºã€è‚¡æƒç­‰
    # ä½¿ç”¨å‰å‘å¡«å……ï¼Œç„¶åŽåŽå‘å¡«å……ï¼Œç¡®ä¿è¿žç»­æ€§
    stock_cols = ['total_hldr_eqy_exc_min_int', 'total_assets', 'total_share']
    for col in stock_cols:
        if col in df.columns:
            # ä½¿ç”¨transformæ¥é¿å…groupbyçš„FutureWarning
            df[col] = df.groupby('ts_code')[col].transform(lambda x: x.ffill().bfill())

    # 3. ç‰¹æ®Šå¤„ç†ï¼šæŸäº›å…³é”®æŒ‡æ ‡å¦‚æžœä»ç„¶ç¼ºå¤±ï¼Œä½¿ç”¨è¡Œä¸šå¹³å‡æˆ–å…¶ä»–æ–¹æ³•
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å¡«å……é€»è¾‘

    # ç»Ÿè®¡å¡«å……ç»“æžœ
    remaining_na = df[flow_cols + stock_cols].isna().sum().sum()
    if remaining_na > 0:
        print(f"âš ï¸  ä»æœ‰ {remaining_na} ä¸ªå€¼æœªå¡«å……")
    else:
        print("âœ… æ•°æ®å¡«å……å®Œæˆï¼Œæ— å‰©ä½™ç¼ºå¤±å€¼")

    quarterly_columns = ['n_income_attr_p', 'total_revenue', 'im_net_cashflow_oper_act']
    # Add optional quarterly columns that might not exist in all datasets
    optional_quarterly_cols = ['total_cogs', 'oper_cost']
    for col in optional_quarterly_cols:
        if col in df.columns:
            quarterly_columns.append(col)

    # ä½¿ç”¨itertools.groupbyæ¥é¿å…pandas groupbyçš„FutureWarning
    df = df.sort_values(['ts_code', 'report_period'])
    groups = []
    for ts_code, group in itertools.groupby(df.iterrows(), key=lambda x: x[1]['ts_code']):
        group_df = pd.DataFrame([row[1] for row in group])
        groups.append((ts_code, group_df))

    processed_groups = [calculate_quarterly_values(group, quarterly_columns) for ts_code, group in groups]
    df = pd.concat(processed_groups, ignore_index=True)

    # Sort by ts_code and report_period
    df = df.sort_values(['ts_code', 'report_period'])

    # Calculate rolling TTM sums for quarterly values
    ttm_columns = {col: 'ttm_' + col for col in quarterly_columns}
    for q_col, ttm_col in ttm_columns.items():
        df[ttm_col] = df.groupby('ts_code')['q_' + q_col].rolling(window=4, min_periods=4).sum().reset_index(level=0, drop=True)

    # Drop rows where TTM is NaN (insufficient history)
    #df = df.dropna(subset=list(ttm_columns.values()))

    # Calculate TTM gross (only if oper_cost data is available)
    if 'ttm_oper_cost' in df.columns:
        df['ttm_gross'] = df['ttm_total_revenue'] - df['ttm_oper_cost']
    else:
        df['ttm_gross'] = df['ttm_total_revenue']  # Fallback if no cost data

    # Per-share calculations (vectorized)
    df['eps_ttm'] = np.where(df['total_share'] > 0, df['ttm_n_income_attr_p'] / df['total_share'], 0)
    df['revenue_ps_ttm'] = np.where(df['total_share'] > 0, df['ttm_total_revenue'] / df['total_share'], 0)
    df['ocfps_ttm'] = np.where(df['total_share'] > 0, df['ttm_im_net_cashflow_oper_act'] / df['total_share'], 0)
    df['cfps_ttm'] = df['ocfps_ttm']  # Assuming CFPS uses OCF

    # ROE and ROA (using period-end values)
    df['roe_ttm'] = np.where(df['total_hldr_eqy_exc_min_int'] > 0,
                             (df['ttm_n_income_attr_p'] / df['total_hldr_eqy_exc_min_int']) * 100, 0)
    df['roa_ttm'] = np.where(df['total_assets'] > 0,
                             (df['ttm_n_income_attr_p'] / df['total_assets']) * 100, 0)

    # Margins
    df['netprofit_margin_ttm'] = np.where(df['ttm_total_revenue'] > 0,
                                          (df['ttm_n_income_attr_p'] / df['ttm_total_revenue']) * 100, 0)
    # Gross margin only if cost data is available
    if 'ttm_oper_cost' in df.columns:
        df['grossprofit_margin_ttm'] = np.where(df['ttm_total_revenue'] > 0,
                                                (df['ttm_gross'] / df['ttm_total_revenue']) * 100, 0)
    else:
        df['grossprofit_margin_ttm'] = np.nan

    # CAGR (3-year, same quarter) with special handling for negative values
    df['revenue_3y_ago'] = df.groupby('ts_code')['total_revenue'].shift(12)
    df['ni_3y_ago'] = df.groupby('ts_code')['n_income_attr_p'].shift(12)

    # Revenue CAGR calculation with negative value handling
    df['revenue_cagr_3y'] = np.nan

    # Both positive (normal CAGR)
    mask_both_positive = (df['revenue_3y_ago'] > 0) & (df['total_revenue'] > 0)
    df.loc[mask_both_positive, 'revenue_cagr_3y'] = (
        (df.loc[mask_both_positive, 'total_revenue'] / df.loc[mask_both_positive, 'revenue_3y_ago']) ** (1/3) - 1
    ) * 100

    # Net Income CAGR calculation with similar logic
    df['netincome_cagr_3y'] = np.nan

    # Both positive (normal CAGR)
    mask_both_positive_ni = (df['ni_3y_ago'] > 0) & (df['n_income_attr_p'] > 0)
    df.loc[mask_both_positive_ni, 'netincome_cagr_3y'] = (
        (df.loc[mask_both_positive_ni, 'n_income_attr_p'] / df.loc[mask_both_positive_ni, 'ni_3y_ago']) ** (1/3) - 1
    ) * 100

    # FCF TTM (Free Cash Flow) - approximation using available data
    # FCF = Operating Cash Flow - CapEx
    if 'n_cashflow_act' in df.columns and 'c_pay_acq_const_fiolta' in df.columns:
        df['fcf_ttm'] = df['n_cashflow_act'] - df['c_pay_acq_const_fiolta'].fillna(0)
    elif 'n_cashflow_act' in df.columns:
        df['fcf_ttm'] = df['n_cashflow_act'] * 0.8  # Rough approximation
    else:
        df['fcf_ttm'] = np.nan

    # FCF Margin TTM
    df['fcf_margin_ttm'] = np.where(df['ttm_total_revenue'] > 0,
                                    (df['fcf_ttm'] / df['ttm_total_revenue']) * 100, np.nan)

    # Debt to EBITDA TTM ratio
    if 'total_liab' in df.columns and 'ebitda' in df.columns:
        df['debt_to_ebitda_ttm'] = np.where(df['ebitda'] > 0, df['total_liab'] / df['ebitda'], np.nan)
    else:
        df['debt_to_ebitda_ttm'] = np.nan

    # Round results
    round_cols = ['eps_ttm', 'revenue_ps_ttm', 'ocfps_ttm', 'cfps_ttm', 'roe_ttm', 'roa_ttm',
                  'netprofit_margin_ttm', 'grossprofit_margin_ttm', 'revenue_cagr_3y', 'netincome_cagr_3y',
                  'fcf_margin_ttm', 'debt_to_ebitda_ttm']
    df[round_cols] = df[round_cols].round(4)

    # Remove filled rows (missing=1) after calculations are complete
    if 'missing' in df.columns:
        original_count = len(df)
        df = df[df['missing'] != 1].copy()
        removed_count = original_count - len(df)
        if removed_count > 0:
            print(f"Removed {removed_count} filled rows after TTM/CAGR calculations")
        df = df.drop(columns=['missing'])

    return df


def convert_wan_to_yuan(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convert stored ä¸‡å…ƒ values back to å…ƒ for API responses
    This ensures API consumers get data in the expected å…ƒ format

    Args:
        df: DataFrame with values stored in ä¸‡å…ƒ

    Returns:
        DataFrame with monetary values converted back to å…ƒ
    """
    if df.empty:
        return df

    df_copy = df.copy()

    # Convert ä¸‡å…ƒ back to å…ƒ for monetary amount fields
    for col in YUAN_TO_WAN_FIELDS:
        if col in df_copy.columns and df_copy[col].notna().any():
            # Convert ä¸‡å…ƒ to å…ƒ (multiply by 10,000)
            df_copy[col] = df_copy[col] * 10000.0

    return df_copy


def _coerce_schema(df: pd.DataFrame) -> pd.DataFrame:
    """Ensure all expected columns exist and normalize data types"""
    # Ensure all expected columns exist
    for col in ALL_COLUMNS:
        if col not in df.columns:
            df[col] = None

    # Keep only known columns, in order
    out = df[ALL_COLUMNS].copy()

    # Normalize types
    if not out.empty:
        # String columns (excluding date columns that will be converted to DATE type)
        string_cols = ["ts_code", "period", "currency"]
        for col in string_cols:
            if col in out.columns:
                out[col] = out[col].astype(str).replace('nan', None).replace('None', None)

        # Convert date columns from string to DATE objects for efficient storage and queries
        # This avoids SQL-level date conversion and improves insertion performance
        # Convert report_period from '2024-03-31' format to DATE object
        if 'report_period' in out.columns:
            out['report_period'] = pd.to_datetime(out['report_period'], format='%Y-%m-%d', errors='coerce').dt.date

        # Convert ann_date from '20240331' format to DATE object
        if 'ann_date' in out.columns:
            out['ann_date'] = pd.to_datetime(out['ann_date'], format='%Y%m%d', errors='coerce').dt.date

        # Numeric columns - convert to float first, then handle None values
        # Exclude string columns and date columns (report_period, ann_date)
        date_cols = ["report_period", "ann_date"]
        numeric_cols = [col for col in ALL_COLUMNS if col not in string_cols and col not in date_cols]
        for col in numeric_cols:
            if col in out.columns:
                out[col] = pd.to_numeric(out[col], errors="coerce")

        # Convert monetary amounts from å…ƒ to ä¸‡å…ƒ for storage
        # This reduces storage space and prevents DECIMAL overflow
        for col in YUAN_TO_WAN_FIELDS:
            if col in out.columns and out[col].notna().any():
                # Convert å…ƒ to ä¸‡å…ƒ (divide by 10,000)
                original_values = out[col].copy()
                out[col] = out[col] / 10000.0

                # Log conversion for large values
                large_conversions = original_values.abs() > 1000000000  # > 10äº¿
                if large_conversions.any():
                    max_original = original_values[large_conversions].max()
                    converted = out[col][large_conversions].max()
                    print(f"Converted {col}: {max_original:.0f}å…ƒ â†’ {converted:.4f}ä¸‡å…ƒ")

                print(f"Converted {col} from å…ƒ to ä¸‡å…ƒ for storage")

        # Validate and clamp numeric values to prevent DECIMAL overflow
        # After conversion to ä¸‡å…ƒ, the limits are much more generous:
        # - DECIMAL(16,4): max ~999,999,999,999ä¸‡å…ƒ (999ä¸‡äº¿), min ~-999,999,999,999ä¸‡å…ƒ
        # - DECIMAL(18,4): max ~99,999,999,999,999ä¸‡å…ƒ (99ä¸‡äº¿), min ~-99,999,999,999,999ä¸‡å…ƒ
        # - DECIMAL(22,4): max ~99,999,999,999,999,999ä¸‡å…ƒ (99ä¸‡äº¿), min ~-99,999,999,999,999,999ä¸‡å…ƒ
        decimal_limits = {
            # After å…ƒâ†’ä¸‡å…ƒ conversion, limits are very generous for most financial data
            'total_revenue': (16, 4),           # DECIMAL(16,4) - up to ~999ä¸‡äº¿ä¸‡å…ƒ
            'revenue': (16, 4),                 # DECIMAL(16,4)
            'operate_profit': (16, 4),          # DECIMAL(16,4)
            'total_profit': (16, 4),            # DECIMAL(16,4)
            'n_income_attr_p': (16, 4),         # DECIMAL(16,4)
            'basic_eps': None,                  # FLOAT - per-share metrics remain in å…ƒ
            'total_cogs': (16, 4),              # DECIMAL(16,4)
            'oper_cost': (16, 4),               # DECIMAL(16,4)
            'sell_exp': (16, 4),                # DECIMAL(16,4)
            'admin_exp': (16, 4),               # DECIMAL(16,4)
            'fin_exp': (16, 4),                 # DECIMAL(16,4)
            'invest_income': (16, 4),           # DECIMAL(16,4)
            'interest_exp': (16, 4),            # DECIMAL(16,4)
            'oper_exp': (16, 4),                # DECIMAL(16,4)
            'ebit': (16, 4),                    # DECIMAL(16,4)
            'ebitda': (16, 4),                  # DECIMAL(16,4)
            'income_tax': (16, 4),              # DECIMAL(16,4)
            'comshare_payable_dvd': (16, 4),    # DECIMAL(16,4)

            # Balance sheet fields - very generous limits after conversion
            'total_assets': (16, 4),            # DECIMAL(16,4)
            'total_liab': (16, 4),              # DECIMAL(16,4)
            'total_hldr_eqy_inc_min_int': (16, 4), # DECIMAL(16,4)
            'total_cur_assets': (16, 4),        # DECIMAL(18,4)
            'total_cur_liab': (16, 4),          # DECIMAL(18,4)
            'accounts_receiv': (16, 4),         # DECIMAL(16,4)
            'inventories': (16, 4),             # DECIMAL(16,4)
            'acct_payable': (16, 4),            # DECIMAL(16,4)
            'fix_assets': (16, 4),              # DECIMAL(16,4)
            'lt_borr': (16, 4),                 # DECIMAL(16,4)
            'r_and_d': (16, 4),                 # DECIMAL(16,4)
            'goodwill': (16, 4),                # DECIMAL(16,4)
            'intang_assets': (16, 4),           # DECIMAL(16,4)
            'st_borr': (16, 4),                 # DECIMAL(16,4)
            'total_share': (16, 4),             # DECIMAL(16,4)
            'oth_eqt_tools_p_shr': (16, 4),     # DECIMAL(16,4)

            # Cash flow fields
            'n_cashflow_act': (16, 4),          # DECIMAL(16,4)
            'n_cashflow_inv_act': (16, 4),      # DECIMAL(16,4)
            'n_cash_flows_fnc_act': (16, 4),    # DECIMAL(16,4)
            'free_cashflow': (16, 4),           # DECIMAL(16,4)
            'c_pay_acq_const_fiolta': (16, 4),  # DECIMAL(16,4)
            'c_fr_sale_sg': (16, 4),            # DECIMAL(16,4)
            'c_paid_goods_s': (16, 4),          # DECIMAL(16,4)
            'c_paid_to_for_empl': (16, 4),      # DECIMAL(16,4)
            'c_paid_for_taxes': (16, 4),        # DECIMAL(16,4)
            'n_incr_cash_cash_equ': (16, 4),    # DECIMAL(16,4)
            'c_disp_withdrwl_invest': (16, 4),  # DECIMAL(16,4)
            'c_pay_dist_dpcp_int_exp': (16, 4), # DECIMAL(16,4)
            'c_cash_equ_end_period': (16, 4),   # DECIMAL(16,4)

            # Financial indicator fields (ratios/per-share metrics - no conversion)
            'eps': None,                        # FLOAT - per-share (å…ƒ)
            'dt_eps': None,                     # FLOAT - per-share (å…ƒ)
            'gross_margin': None,               # FLOAT - ratio (%)
            'netprofit_margin': None,           # FLOAT - ratio (%)
            'grossprofit_margin': None,         # FLOAT - ratio (%)
            'ebitda_margin': None,              # FLOAT - ratio (%)
            'extra_item': (16, 4),              # DECIMAL(16,4) - monetary amount
            'profit_dedt': (16, 4),             # DECIMAL(16,4) - monetary amount
            'op_income': (16, 4),               # DECIMAL(16,4) - monetary amount
            'daa': (16, 4),                     # DECIMAL(16,4) - monetary amount
            'rd_exp': (16, 4),                  # DECIMAL(16,4) - monetary amount

            # Most other indicator fields are FLOAT (ratios) or smaller ranges
            # For safety, we'll use conservative limits for large values
        }

        # Add conservative default limits for any DECIMAL fields not explicitly defined
        # This handles cases where the database schema might differ from our assumptions
        default_decimal_limit = (16, 4)  # Conservative default: DECIMAL(16,4)

        # Check for any numeric columns that might be DECIMAL but aren't in our limits dict
        for col in numeric_cols:
            if col not in out.columns:
                continue

            if col not in decimal_limits:
                # Check if column might contain large values that could overflow
                col_values = pd.to_numeric(out[col], errors='coerce')
                if col_values.notna().any():
                    max_val = col_values.abs().max()  # Check absolute value
                    if max_val > 1000000000:  # If greater than 1 billion
                        # Apply conservative limit to prevent overflow
                        precision, scale = default_decimal_limit
                        max_allowed = 10 ** (precision - scale) - (10 ** (-scale))
                        min_allowed = -max_allowed

                        if max_val > max_allowed:
                            print(f"Warning: {col} has large value {max_val}, applying conservative limit")
                            out[col] = out[col].clip(lower=min_allowed, upper=max_allowed)

        # Apply decimal limits to prevent overflow
        for col in numeric_cols:
            if col in out.columns and decimal_limits.get(col) is not None:
                precision, scale = decimal_limits[col]
                max_value = 10 ** (precision - scale) - (10 ** (-scale))
                min_value = -max_value

                # Debug: Check for values that exceed limits before clamping
                if out[col].notna().any():
                    original_series = pd.to_numeric(out[col], errors='coerce')
                    exceeding_max = original_series > max_value
                    exceeding_min = original_series < min_value

                    if exceeding_max.any():
                        max_val = original_series[exceeding_max].max()
                        print(f"Warning: {col} has value {max_val} exceeding max {max_value}")
                    if exceeding_min.any():
                        min_val = original_series[exceeding_min].min()
                        print(f"Warning: {col} has value {min_val} below min {min_value}")

                # Clamp values to valid range
                out[col] = out[col].clip(lower=min_value, upper=max_value)

                # Log clamping results
                if out[col].notna().any():
                    final_max = pd.to_numeric(out[col], errors='coerce').max()
                    final_min = pd.to_numeric(out[col], errors='coerce').min()
                    if final_max == max_value:
                        print(f"Info: {col} clamped to max value {max_value}")
                    if final_min == min_value:
                        print(f"Info: {col} clamped to min value {min_value}")

        # Ensure DB NULLs: cast to object then replace NaN with None
        out = out.astype(object).where(pd.notna(out), None)
        # Extra safety for numpy.nan
        out = out.replace({np.nan: None})

    return out


def _fetch_single_period_data(report_period: str) -> pd.DataFrame:
    """
    Fetch financial data for a single period

    âœ¨ Optimization features:
    - Retry mechanism: Each API call retries up to 3 times with exponential backoff
    - Smart merging: Merge all data sources at once, supports partial data
    - Error recovery: Failure of one data source doesn't affect others
    - Detailed logging: Complete data fetching and merging process records
    - Simplified configuration: Field names identical to API, no mapping table needed

    Data merging strategy:
    1. Three major financial statements (Income + Balance + Cash Flow) use common keys for merging
    2. Financial indicator data uses simplified keys for merging (no report_type field)
    3. Supports partial data scenarios, returns results even with only partial data sources

    Field configuration optimization:
    - COMMON_FIELDS: Common fields for three major statements ['ts_code', 'ann_date', 'end_date', 'report_type']
    - INDICATOR_BASE_FIELDS: Base fields for financial indicators ['ts_code', 'ann_date', 'end_date']
    - Use field lists directly, no redundant mapping table

    Args:
        report_period: Report period, format like '20231231'

    Returns:
        Merged financial data DataFrame containing all available data
    """
    try:
        print(f"Fetching financial data for period: {report_period}")

        # 1. Get income statement data (with retry mechanism)
        income_fields = API_COMMON_FIELDS + INCOME_COLUMNS
        income_df = call_tushare_api_with_retry(
            pro.income_vip,
            period=report_period,
            fields=','.join(income_fields)
        )

        # 2. Get balance sheet data (with retry mechanism)
        balance_fields = API_COMMON_FIELDS + BALANCE_COLUMNS
        balance_df = call_tushare_api_with_retry(
            pro.balancesheet_vip,
            period=report_period,
            fields=','.join(balance_fields)
        )

        # 3. Get cash flow statement data (with retry mechanism)
        cashflow_fields = API_COMMON_FIELDS + CASHFLOW_COLUMNS
        cashflow_df = call_tushare_api_with_retry(
            pro.cashflow_vip,
            period=report_period,
            fields=','.join(cashflow_fields)
        )

        # 4. Get financial indicators data (with retry mechanism)
        indicator_fields = INDICATOR_BASE_FIELDS + INDICATOR_COLUMNS
        indicator_df = call_tushare_api_with_retry(
            pro.fina_indicator_vip,
            period=report_period,
            fields=','.join(indicator_fields)
        )

        # === Merge data by source grouping ===

        # Check availability of each data source
        data_sources = {
            'income_statement': income_df,
            'balance_sheet': balance_df,
            'cash_flow': cashflow_df,
            'financial_indicators': indicator_df
        }

        available_sources = {name: df for name, df in data_sources.items() if not df.empty}
        if not available_sources:
            print(f"No data available for period {report_period}")
            return pd.DataFrame()

        print(f"Available data sources for period {report_period}: {', '.join(available_sources.keys())}")

        # Debug: Print record counts for each data source
        for name, df in available_sources.items():
            if len(df) > 0:
                # Remove duplicates within each data source before merging
                # Keep the last record (potentially more updated/corrected data)
                initial_len = len(df)
                df = df.drop_duplicates(subset=['ts_code', 'ann_date', 'end_date'], keep='last')
                if len(df) < initial_len:
                    print(f"Removed {initial_len - len(df)} duplicates from {name} (kept latest)")

                available_sources[name] = df

        # Merge strategy: connect by data source grouping
        merged_df = None

        # 1. Merge three major financial statements (Income + Balance + Cash Flow)
        # These data sources have the same join keys: ['ts_code', 'ann_date', 'end_date', 'report_type']
        financial_statements = []
        if 'income_statement' in available_sources:
            financial_statements.append(available_sources['income_statement'])
        if 'balance_sheet' in available_sources:
            financial_statements.append(available_sources['balance_sheet'])
        if 'cash_flow' in available_sources:
            financial_statements.append(available_sources['cash_flow'])

        if financial_statements:
            try:
                # Start from the first data source and gradually merge other data sources
                merged_df = financial_statements[0]
                print(f"Initial merge base: {len(merged_df)} records from {list(available_sources.keys())[0]}")

                for i, df in enumerate(financial_statements[1:], 1):
                    before_count = len(merged_df)
                    source_name = list(available_sources.keys())[i]

                    # Check merge keys before merging
                    merge_keys_check = merged_df.groupby(API_COMMON_FIELDS).size()
                    incoming_keys_check = df.groupby(API_COMMON_FIELDS).size()

                    merged_df = merged_df.merge(
                        df,
                        on=API_COMMON_FIELDS,
                        how='outer'
                    )
                    after_count = len(merged_df)
                    print(f"After: {after_count} records (+{after_count - before_count})")

                print(f"Successfully merged {len(financial_statements)} financial statements: {len(merged_df)} records")
            except Exception as e:
                print(f"Error merging financial statements: {e}")
                return pd.DataFrame()

        # 2. Merge financial indicators data
        # Financial indicators data doesn't have 'report_type' field, use simplified join keys
        if merged_df is not None and 'financial_indicators' in available_sources:
            try:
                before_count = len(merged_df)
                indicator_df = available_sources['financial_indicators']

                # Check merge keys
                base_keys = merged_df.groupby(['ts_code', 'ann_date', 'end_date']).size()
                indicator_keys = indicator_df.groupby(['ts_code', 'ann_date', 'end_date']).size()

                print(f"Financial indicators merge:")
                print(f"Base data: {len(base_keys)} unique combinations, {before_count} total records")
                print(f"Indicators: {len(indicator_keys)} unique combinations, {len(indicator_df)} total records")

                merged_df = merged_df.merge(
                    indicator_df,
                    on=['ts_code', 'ann_date', 'end_date'],
                    how='left'  # Left join to ensure financial data completeness
                )
                after_count = len(merged_df)
                print(f"  Result: {after_count} records ({'+' if after_count > before_count else ''}{after_count - before_count})")
                print(f"Successfully merged financial indicators: {len(merged_df)} records total")
            except Exception as e:
                print(f"Error merging financial indicators: {e}")
                print("Continuing with financial statements only...")

        # Handle edge case: only financial indicators data, no major financial statements
        elif merged_df is None and 'financial_indicators' in available_sources:
            merged_df = available_sources['financial_indicators'].copy()
            print(f"Using financial indicators only: {len(merged_df)} records")

        if merged_df is None:
            print(f"No usable data after merging for period {report_period}")
            return pd.DataFrame()

        # Add unified fields
        try:
            merged_df['ts_code'] = merged_df['ts_code']

            # Keep the original ann_date from API - don't override with end_date
            # ann_date represents when the financial report was actually announced
            # end_date represents the end of the reporting period
            if 'ann_date' not in merged_df.columns or merged_df['ann_date'].isna().all():
                # Fallback to end_date only if ann_date is missing
                merged_df['ann_date'] = merged_df['end_date']
                print(f"Warning: Using end_date as ann_date fallback for period {report_period}")
            else:
                # Validate ann_date makes sense (should be after end_date)
                sample_ann_date = merged_df['ann_date'].iloc[0]
                sample_end_date = merged_df['end_date'].iloc[0]
                print(f"Using API ann_date: {sample_ann_date} (end_date: {sample_end_date}) for period {report_period}")

            # Convert report_period to DATE object directly from end_date
            # This creates a proper DATE object for the reporting period end date
            merged_df['report_period'] = pd.to_datetime(merged_df['end_date'], format='%Y%m%d').dt.date
            merged_df['period'] = 'annual' if report_period.endswith('1231') else 'quarter'
            merged_df['currency'] = 'CNY'  # A-share default currency is CNY

            # Remove API-specific fields that don't exist in database
            if 'end_date' in merged_df.columns:
                merged_df = merged_df.drop('end_date', axis=1)

            # Remove duplicates based on primary key (ts_code, report_period)
            # Keep the last record (potentially more updated/corrected data)
            initial_count = len(merged_df)

            # Debug: Check for duplicates before removal
            duplicate_check = merged_df.groupby(['ts_code', 'report_period']).size()
            duplicates_found = duplicate_check[duplicate_check > 1]
            if len(duplicates_found) > 0:
                print(f"Found {len(duplicates_found)} duplicate groups before removal:")
                for (ts_code, report_period), count in duplicates_found.items():
                    print(f"  {ts_code} {report_period}: {count} duplicates")

            merged_df = merged_df.drop_duplicates(subset=['ts_code', 'report_period'], keep='last')
            final_count = len(merged_df)

            if initial_count != final_count:
                print(f"Removed {initial_count - final_count} duplicate records, kept {final_count} unique records (latest)")
            else:
                print(f"No duplicates found, kept {final_count} records")

            print(f"Successfully processed {len(merged_df)} financial records for period {report_period}")
            return merged_df

        except Exception as e:
            print(f"Error processing unified fields: {e}")
            return pd.DataFrame()

    except Exception as e:
        print(f"Error in _fetch_single_period_data for period {report_period}: {e}")
        return pd.DataFrame()


def _generate_periods(end_date: str, period: str = "annual", limit: int = 1) -> List[str]:
    """Generate list of periods that need to be processed"""
    periods = []
    end_dt = datetime.datetime.strptime(end_date, "%Y%m%d")

    if period == "annual":
        # Annual reports: Get the most recent years' 12-31
        for i in range(limit):
            year = end_dt.year - i
            if datetime.datetime(year, 12, 31) <= end_dt:
                periods.append(f"{year}1231")
    else:
        # Quarterly reports: Get the most recent quarters' end dates
        quarters = [(3, 31), (6, 30), (9, 30), (12, 31)]
        current_quarter = None

        # Find current quarter
        for month, day in reversed(quarters):
            q_date = datetime.datetime(end_dt.year, month, day)
            if q_date <= end_dt:
                current_quarter = q_date
                break

        if current_quarter:
            for i in range(limit):
                periods.append(current_quarter.strftime("%Y%m%d"))
                # Calculate previous quarter
                if current_quarter.month == 3:
                    current_quarter = datetime.datetime(current_quarter.year - 1, 12, 31)
                elif current_quarter.month == 6:
                    current_quarter = datetime.datetime(current_quarter.year, 3, 31)
                elif current_quarter.month == 9:
                    current_quarter = datetime.datetime(current_quarter.year, 6, 30)
                else:  # 12
                    current_quarter = datetime.datetime(current_quarter.year, 9, 30)

    return periods


def _fetch_financial_data(end_date: str, period: str = "annual", limit: int = 1) -> pd.DataFrame:
    """Fetch financial data for multiple periods (maintain compatibility)"""
    periods = _generate_periods(end_date, period, limit)

    if not periods:
        print("No valid periods found")
        return pd.DataFrame()

    print(f"Fetching financial data for periods: {periods}")

    all_data = []
    for report_period in periods:
        df = _fetch_single_period_data(report_period)
        if not df.empty:
            all_data.append(df)

        # Add delay to avoid API limits
        time.sleep(0.5)

    if all_data:
        result_df = pd.concat(all_data, ignore_index=True)
        print(f"Successfully fetched {len(result_df)} financial records in total")
        return result_df
    else:
        return pd.DataFrame()


def _upsert_batch(engine, df: pd.DataFrame, chunksize: int = 1000) -> int:
    """Batch upsert data to MySQL

    Returns:
        int: Number of records processed (not necessarily inserted/updated)
    """
    if df is None or df.empty:
        return 0

    # Return the actual number of records in the DataFrame, not the SQL result rowcount
    # This gives a more accurate representation of processed records
    total_processed = len(df)

    meta = MetaData()
    table = Table(TABLE_NAME, meta, autoload_with=engine)

    rows = df.to_dict(orient="records")
    total_affected = 0

    with engine.begin() as conn:
        for i in range(0, len(rows), chunksize):
            batch = rows[i:i+chunksize]
            stmt = mysql_insert(table).values(batch)
            update_map: Dict[str, Any] = {
                c: getattr(stmt.inserted, c)
                for c in ALL_COLUMNS
                if c not in ("ts_code", "report_period", "ann_date")  # Exclude primary key and date fields from updates
            }
            ondup = stmt.on_duplicate_key_update(**update_map)
            result = conn.execute(ondup)
            total_affected += result.rowcount or 0

    # Log both metrics for transparency
    print(f"Processed {total_processed} records, database reported {total_affected} affected rows")
    return total_processed


def update_a_stock_financial_profile(
    mysql_url: str = "mysql+pymysql://root:@127.0.0.1:3306/investment_data",
    end_date: Optional[str] = None,
    period: str = "quarter",
    limit: int = 10,
    chunksize: int = 1000,
) -> None:
    """
    Incrementally fetch Tushare financial profile data and write to MySQL ts_a_stock_financial_profile table

    âœ¨ Optimization features:
    - Period-by-period processing: Avoid memory overflow from loading too much data at once
    - Real-time writing: Write to database immediately after processing each period
    - Memory-friendly: Release memory immediately after processing each period's data
    - ðŸ”„ Retry mechanism: Automatically retry API calls up to 3 times with exponential backoff

    Contains complete financial data, grouped by relevance:
    1. Three major financial statements: Income statement, Balance sheet, Cash flow statement
    2. Basic financial indicators: Gross margin, net margin and other basic indicators
    3. Solvency indicators: Current ratio, quick ratio, debt-to-assets ratio, etc.
    4. Operating efficiency indicators: Turnover ratios, operating efficiency, etc.
    5. Profitability indicators: ROE, ROA, net margin, etc.
    6. DuPont analysis indicators: Equity multiplier, ROE decomposition, etc.
    7. Per share indicators: Earnings per share, book value per share, etc.
    8. Cash flow indicators: Cash flow ratios, cash flow efficiency, etc.
    9. Growth indicators: Various business growth rates
    10. Quarterly financial indicators: Quarterly data and ratios
    11. Cost and expense structure analysis: Expense ratio analysis
    12. Asset structure analysis: Asset allocation and capital structure
    13. Valuation indicators: Market value, intrinsic value, etc.

    Data sources:
    - pro.income_vip() - Income statement
    - pro.balancesheet_vip() - Balance sheet
    - pro.cashflow_vip() - Cash flow statement
    - pro.fina_indicator_vip() - Financial indicators

    Data type optimization:
    - Ratios and per-share earnings: FLOAT type (precise to 6 decimal places)
    - Absolute amounts: DECIMAL(16,4) type (precise to cent)
    - Date fields: DATE type (report_period, ann_date) for efficient date operations and storage

    Field configuration optimization:
    - Field names identical to Tushare API, no mapping table needed
    - Use COMMON_FIELDS and INDICATOR_BASE_FIELDS for simplified configuration
    - Four major data source groups: Income statement, Balance sheet, Cash flow, Financial indicators

    Processing workflow:
    1. Generate list of periods that need processing
    2. Process each period individually:
       - Fetch four major data sources (three major statements + financial indicators)
       - Smart merging: Merge all available data at once
       - Error recovery: Partial data failure doesn't affect the whole process
       - Write to database immediately to free up memory
    3. Statistical processing results

    Data merging optimization:
    - One-time merging strategy: Three major statements â†’ Financial indicators
    - Smart key matching: Select appropriate join keys based on data source characteristics
    - Partial data support: Continue even if some data sources fail
    - Detailed status monitoring: Real-time display of data fetching and merging status

    Retry mechanism details:
    - Each API call failure automatically retries, up to 3 times
    - Retry intervals: 1s â†’ 2s â†’ 4s (exponential backoff)
    - Detailed recording of error information for each retry
    - Failure of one API doesn't affect other API calls

    Args:
        mysql_url: MySQL connection URL
        end_date: End date in YYYYMMDD format, defaults to yesterday
        period: Report period type, 'annual' or 'quarter'
        limit: Limit on number of report periods to fetch
        chunksize: Batch processing size
    """

    # Set end date
    if end_date is None:
        yesterday = datetime.datetime.now() - datetime.timedelta(days=1)
        end_date = yesterday.strftime("%Y%m%d")

    print(f"Starting to update financial profile data, end date: {end_date}, period type: {period}, limit: {limit}")

    # Create database engine
    engine = create_engine(mysql_url, pool_recycle=3600)

    # Create table structure
    with engine.begin() as conn:
        conn.execute(text(CREATE_TABLE_DDL))

    # Fetch and process financial profile data period by period
    print("Fetching and processing financial profile data period by period...")

    periods = _generate_periods(end_date, period, limit)
    if not periods:
        print("No valid periods found")
        return

    # Collect all data first for TTM calculations
    all_data_frames = []
    total_raw_records = 0

    for i, report_period in enumerate(periods):
        print(f"\nProcessing period {i+1}/{len(periods)}: {report_period}")

        # Get data for single period
        df = _fetch_single_period_data(report_period)

        if df.empty:
            print(f"No data retrieved for period {report_period}, skipping")
            continue

        # Data normalization
        df = _coerce_schema(df)
        all_data_frames.append(df)
        total_raw_records += len(df)

        print(f"Retrieved {len(df)} financial profile records for period {report_period}")

        # Add delay to avoid API limits (already added in _fetch_single_period_data)
        if i < len(periods) - 1:  # Not the last period, add delay
            time.sleep(0.5)

    if not all_data_frames:
        print("No data retrieved for any period")
        return

    # Combine all data for TTM calculations
    combined_df = pd.concat(all_data_frames, ignore_index=True)
    print(f"\nCombined {len(all_data_frames)} periods into {len(combined_df)} total records")

    # Calculate TTM indicators
    print("Calculating TTM (Trailing Twelve Months) indicators...")
    combined_df = calculate_ttm_indicators(combined_df)
    print(f"TTM calculation completed, {len(combined_df)} records after TTM processing")

    # Upsert to database in batches
    total_written = _upsert_batch(engine, combined_df, chunksize=chunksize)

    print(f"\nUpdate completed:")
    print(f"- Processed {len(periods)} periods")
    print(f"- Retrieved {total_raw_records} raw records")
    print(f"- Final records after TTM calculation: {len(combined_df)}")
    print(f"- Total records written to database: {total_written}")


if __name__ == "__main__":
    fire.Fire(update_a_stock_financial_profile)
